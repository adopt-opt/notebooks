{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Working with Jaxfluids\n",
    "\n",
    "(Introductory) notebook on working with [Jaxfluids](https://github.com/adopt-opt/jaxfluids) in the context of design optimization. For installation instructions of the underlying JAX package, please see their [GitHub repository](https://github.com/google/jax)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Manipulation of JSON\n",
    "\n",
    "For the manipulation of the JSON files we want to use [PyJSON](https://github.com/niyoh120/pyjson), with which we can then alter the entries of our JSON files."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import json"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Storing the path to our two most important JSON files into variables"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "case_setup = './cylinderflow.json'\n",
    "num_setup = './numerical_setup.json'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Altering the JSON file"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "jsonFile = open(case_setup, \"r\") # Open the JSON file for reading\n",
    "setup = json.load(jsonFile) # Read the JSON into the buffer\n",
    "jsonFile.close() # Close the JSON file\n",
    "\n",
    "## Working with buffered content\n",
    "setup[\"domain\"][\"x\"][\"cells\"] = 75\n",
    "setup[\"domain\"][\"x\"][\"range\"] = [-2, 4]\n",
    "setup[\"domain\"][\"y\"][\"cells\"] = 50\n",
    "setup[\"domain\"][\"y\"][\"range\"] = [-2, 2]\n",
    "\n",
    "## Save our changes to JSON file\n",
    "jsonFile = open(case_setup, \"w+\")\n",
    "jsonFile.write(json.dumps(setup))\n",
    "jsonFile.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The same approach can be replicated for other tasks such as changing the lambda function determining the shape of the body inside of the domain for design optimization purposes\n",
    "\n",
    "```json\n",
    "{\n",
    "\"initial_condition\": {\n",
    "        \"primes\":{\n",
    "            \"rho\": 1.0,\n",
    "            \"u\": 0.0,\n",
    "            \"v\": 0.0,\n",
    "            \"w\": 0.0,\n",
    "            \"p\": 1.0\n",
    "        },\n",
    "        \"levelset\": \"lambda x,y: - 0.1 + jnp.sqrt(x**2 + y**2)\"\n",
    "    }\n",
    "}\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Ahead-of-Time (AOT) Compilation with JAX\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "import jax  # JIT & AOT Compilation\n",
    "import jax.numpy as jnp\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from jaxfluids import InputReader, SimulationManager"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Setting up the simulation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "input_reader = InputReader(\"cylinderflow.json\", \"numerical_setup.json\")\n",
    "sim_manager  = SimulationManager(input_reader)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "case_dict = json.load(open(\"cylinderflow.json\"))\n",
    "numerical_setup_dict = json.load(open(\"numerical_setup.json\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We now seek to ahead-of-time (AOT) compile the simulation, and hence save us from the burden of repeatedly compiling the simulation for that we use a helper function, which allows us to template the setup, an approach which we can copy to get the desired gradients for design optimization as well. As we are missing the usual initialization steps, this has to be done inside of the function, and the cell. I.e. we are missing\n",
    "\n",
    "```python\n",
    "initializer = Initializer(input_reader)\n",
    "buffer_dictionary = initializer.initialization()\n",
    "```\n",
    "\n",
    "plus we are replacing the actual simulation step with only the forward step, and are hence not utilizing\n",
    "\n",
    "```python\n",
    "sim_manager.simulate(buffer_dictionary)\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Pre-Shock Conditions\n",
    "gamma_L, gamma_R = 1.4\n",
    "rho_R = p_R = 1.0\n",
    "a_R   = np.sqrt(gamma_R * p_R / rho_R)\n",
    "u_R   = 0.0\n",
    "M_R   = u_R / a_R\n",
    "\n",
    "def wrapper_fun(M_S: float = 2.0):  # function needs to be specialized to the purpose here\n",
    "    traj_length = 5\n",
    "    time_step   = 1e-2\n",
    "    res = case_dict[\"nx\"]\n",
    "\n",
    "    dx = 1.0 / res\n",
    "    x_cf   = jnp.linspace(0, 1, num=res+1)\n",
    "    x_cc = 0.5 * (x_cf[1:] + x_cf[:-1])\n",
    "\n",
    "    # Post shock rankine huginot condition -> Specific to the case\n",
    "    p_L   = p_R * ( 1/(gamma_L + 1) * (gamma_R * (M_R - M_S)**2 + 1) + jnp.sqrt( (1/(gamma_L + 1) * (gamma_R * (M_R - M_S)**2 + 1))**2 - (gamma_L-1)/(gamma_L+1) * ((M_R-M_S)**2 * 2 * gamma_R/(gamma_R - 1) - 1) ))\n",
    "    rho_L = rho_R *  (gamma_R - 1)/(gamma_L - 1) * ( p_L / p_R + (gamma_L - 1)/ (gamma_L + 1) ) / ( p_L / p_R * (gamma_R - 1) / (gamma_L + 1) + (gamma_R + 1) / (gamma_L + 1) )\n",
    "    u_L   = a_R * ( rho_R/rho_L * (M_R - M_S) + M_S )\n",
    "\n",
    "    # Initializing the buffer\n",
    "    prime_init      = jnp.zeros((1, 5, res, 1, 1))\n",
    "    prime_init      = prime_init.at[0,0,:,0,0].set(jnp.where(x_cc > 0.5, rho_R, rho_L))\n",
    "    prime_init      = prime_init.at[0,1,:,0,0].set(jnp.where(x_cc > 0.5, u_R, u_L))\n",
    "    prime_init      = prime_init.at[0,4,:,0,0].set(jnp.where(x_cc > 0.5, p_R, p_L))\n",
    "    levelset_init   = None\n",
    "\n",
    "    # Forward Simulation\n",
    "    data_series, _ = sim_manager.feed_forward(\n",
    "        prime_init,\n",
    "        levelset_init,\n",
    "        traj_length,\n",
    "        time_step,\n",
    "        0.0, 1, None, None)\n",
    "    data_series = data_series[0]\n",
    "\n",
    "    # Compute Scalar Output Quantities\n",
    "    entropy = data_series[:,4] / data_series[:,0]**gamma_L\n",
    "    total_entropy = jnp.mean(data_series[-1,0] * entropy[-1] - data_series[0,0] * entropy[0])\n",
    "    return total_entropy"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Lower the function to its IR representation\n",
    "lowered_wrapper = jax.jit(wrapper_fun).lower(M_S)\n",
    "#lowered_gradient?\n",
    "\n",
    "# Compile the function itself\n",
    "compiled_wrapper = lowered_wrapper.compile()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "After which we can call our ahead-of-time compiled wrapper function with its arguments\n",
    "\n",
    "* Can I just compile a specialized kernel which computes the gradient, and which I can then bombard with configurations?\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "compiled_wrapper(inputs) # derives its args from the specialized wrapper function from above."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Batch Evaluation with AOT'd wrapper\n",
    "\n",
    "We can now generate a large batch of potential inputs, and just vmap over the entire input_axis. As we have ahead-of-time compiler the function evaluation, we will save a very large swathe of computation due to not having to recompile, fully reevaluate every single execution"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Batch execution to go here"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "To quantify the computational savings we achieve from this we can now evaluate this with varying batch-size (vector lengths), and see just how much faster we can get while cramming the entire computation onto the GPU."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plotting code which takes the above cell as a function, evaluates it for different batch sizes, and then plots them"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
